**Overview**


This project performs text classification of BBC news articles using a DistilBERT transformer model. The dataset contains labeled news articles, and the goal is to predict the category of each article. The project demonstrates fine-tuning a pre-trained transformer on a multi-class classification task with high accuracy.

**Tech**

Python, PyTorch, HuggingFace Transformers, LoRA / PEFT, Retrieval-Augmented Generation (RAG), FAISS, Sentence Transformers, scikit-learn, Streamlit,


**Outcome**


Achieved 86.8% accuracy and 0.74 macro-F1 on held-out test data. Retrieval-augmented prompting improved model reasoning and consistency over zero-shot baselines.The final solution was deployed as an interactive Streamlit web application for real-time, context-aware text classification.




 
